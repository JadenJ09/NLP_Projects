{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (0.0.39)\n",
      "Requirement already satisfied: PyYAML<7,>=6 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from langchain) (1.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[local-inference]\n",
      "  Using cached unstructured-0.7.2-py3-none-any.whl (1.3 MB)\n",
      "Collecting argilla (from unstructured[local-inference])\n",
      "  Using cached argilla-1.8.0-py3-none-any.whl (2.4 MB)\n",
      "Requirement already satisfied: chardet in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (3.0.4)\n",
      "Requirement already satisfied: lxml in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (4.9.2)\n",
      "Collecting msg-parser (from unstructured[local-inference])\n",
      "  Using cached msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (3.8.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (3.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (1.5.3)\n",
      "Collecting pdfminer.six (from unstructured[local-inference])\n",
      "  Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (9.4.0)\n",
      "Collecting pypandoc (from unstructured[local-inference])\n",
      "  Using cached pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx (from unstructured[local-inference])\n",
      "  Using cached python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-pptx (from unstructured[local-inference])\n",
      "  Using cached python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-magic (from unstructured[local-inference])\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: markdown in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (3.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured[local-inference]) (2.28.2)\n",
      "Collecting tabulate (from unstructured[local-inference])\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting xlrd (from unstructured[local-inference])\n",
      "  Using cached xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Collecting unstructured-inference==0.5.1 (from unstructured[local-inference])\n",
      "  Using cached unstructured_inference-0.5.1-py3-none-any.whl (39 kB)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured-inference==0.5.1->unstructured[local-inference]) (0.0.6)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured-inference==0.5.1->unstructured[local-inference]) (0.13.4)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Collecting onnxruntime (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached onnxruntime-1.15.0-cp311-cp311-win_amd64.whl (6.7 MB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from unstructured-inference==0.5.1->unstructured[local-inference]) (4.28.1)\n",
      "Collecting httpx<0.24,>=0.15 (from argilla->unstructured[local-inference])\n",
      "  Using cached httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "Collecting deprecated~=1.2.0 (from argilla->unstructured[local-inference])\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from argilla->unstructured[local-inference]) (23.0)\n",
      "Collecting pydantic>=1.10.7 (from argilla->unstructured[local-inference])\n",
      "  Using cached pydantic-1.10.9-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from argilla->unstructured[local-inference]) (1.14.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from argilla->unstructured[local-inference]) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from argilla->unstructured[local-inference]) (4.65.0)\n",
      "Collecting backoff (from argilla->unstructured[local-inference])\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic (from argilla->unstructured[local-inference])\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting rich<=13.0.1 (from argilla->unstructured[local-inference])\n",
      "  Using cached rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.6.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from argilla->unstructured[local-inference]) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pandas->unstructured[local-inference]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pandas->unstructured[local-inference]) (2022.7.1)\n",
      "Collecting olefile>=0.46 (from msg-parser->unstructured[local-inference])\n",
      "  Using cached olefile-0.46.zip (112 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from nltk->unstructured[local-inference]) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from nltk->unstructured[local-inference]) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from nltk->unstructured[local-inference]) (2022.10.31)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from openpyxl->unstructured[local-inference]) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pdfminer.six->unstructured[local-inference]) (3.1.0)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured[local-inference])\n",
      "  Using cached cryptography-41.0.1-cp37-abi3-win_amd64.whl (2.6 MB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured[local-inference])\n",
      "  Using cached XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests->unstructured[local-inference]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests->unstructured[local-inference]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from requests->unstructured[local-inference]) (2022.12.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[local-inference]) (1.15.1)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured[local-inference])\n",
      "  Using cached httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured[local-inference]) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pydantic>=1.10.7->argilla->unstructured[local-inference]) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->unstructured[local-inference]) (1.16.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich<=13.0.1->argilla->unstructured[local-inference])\n",
      "  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from rich<=13.0.1->argilla->unstructured[local-inference]) (2.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from tqdm>=4.27.0->argilla->unstructured[local-inference]) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (3.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference==0.5.1->unstructured[local-inference]) (0.13.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (1.10.1)\n",
      "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
      "Collecting pdf2image (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.0.0)\n",
      "Collecting torchvision (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached torchvision-0.15.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting coloredlogs (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]) (23.3.3)\n",
      "INFO: pip is looking at multiple versions of onnxruntime to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached layoutparser-0.3.3-py3-none-any.whl (19.2 MB)\n",
      "  Using cached layoutparser-0.3.2-py3-none-any.whl (19.2 MB)\n",
      "  Using cached layoutparser-0.3.1-py3-none-any.whl (19.2 MB)\n",
      "  Using cached layoutparser-0.3.0-py3-none-any.whl (19.2 MB)\n",
      "  Using cached layoutparser-0.2.0-py3-none-any.whl (19.1 MB)\n",
      "  Using cached layoutparser-0.1.3-py3-none-any.whl (19.1 MB)\n",
      "Collecting pycocotools==2.0.1 (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached pycocotools-2.0.1.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fvcore==0.1.1.post20200623 (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached fvcore-0.1.1.post20200623.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting yacs>=0.1.6 (from fvcore==0.1.1.post20200623->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting portalocker (from fvcore==0.1.1.post20200623->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from fvcore==0.1.1.post20200623->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pycocotools==2.0.1->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (67.8.0)\n",
      "Collecting cython>=0.27.3 (from pycocotools==2.0.1->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached Cython-0.29.35-py2.py3-none-any.whl (988 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\jaden\\onedrive\\coding\\program\\python 3.11\\lib\\site-packages (from pycocotools==2.0.1->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]) (3.7.1)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached layoutparser-0.1.2-py3-none-any.whl (19.1 MB)\n",
      "Collecting pycocotools (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of onnxruntime to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference])\n",
      "  Using cached layoutparser-0.1.1-py3-none-any.whl (19.1 MB)\n",
      "INFO: pip is looking at multiple versions of layoutparser[layoutmodels,tesseract] to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached layoutparser-0.1.0-py3-none-any.whl (19.1 MB)\n",
      "  Using cached layoutparser-0.0.1-py3-none-any.whl (10 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    layoutparser[layoutmodels,tesseract] 0.1.1 depends on torch==1.4\n",
      "    layoutparser[layoutmodels,tesseract] 0.1.0 depends on torch==1.4\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: layoutparser 0.2.0 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.2.0 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.2.0 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.2.0 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.3 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.3 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.3 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.3 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.2 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.2 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.2 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.2 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.1 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.1 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.0 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.0 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.0.1 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.0.1 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.0.1 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.0.1 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.1 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.1 does not provide the extra 'tesseract'\n",
      "WARNING: layoutparser 0.1.0 does not provide the extra 'layoutmodels'\n",
      "WARNING: layoutparser 0.1.0 does not provide the extra 'tesseract'\n",
      "ERROR: Cannot install layoutparser[layoutmodels,tesseract]==0.1.0 and layoutparser[layoutmodels,tesseract]==0.1.1 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[local-inference]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Python\\\\ProjectStudy', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\python311.zip', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\DLLs', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\Lib', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11', '', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jaden\\\\OneDrive\\\\Coding\\\\Program\\\\Python 3.11\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Youtube_llm\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m YoutubeLoader\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.document_loaders'"
     ]
    }
   ],
   "source": [
    "# Youtube_llm\n",
    "\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import textwrap\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "def create_db_from_youtube_video_url(video_url: str) -> FAISS:\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    \"\"\"\n",
    "    text-davinci-003 can handle up to 4097 tokens. Setting the chunksize to 1000 and k to 4 maximizes\n",
    "    the number of tokens to analyze.\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"docs\"],\n",
    "        template=\"\"\"\n",
    "        You are a helpful assistant that that can answer questions about youtube videos \n",
    "        based on the video's transcript.\n",
    "        \n",
    "        Answer the following question: {question}\n",
    "        By searching the following video transcript: {docs}\n",
    "        \n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
    "db = create_db_from_youtube_video_url(video_url)\n",
    "\n",
    "query = \"What are they saying about Microsoft?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.document_loaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Youtube_chat\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m YoutubeLoader\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.document_loaders'"
     ]
    }
   ],
   "source": [
    "# Youtube_chat\n",
    "import yaml\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "import textwrap\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "def create_db_from_youtube_video_url(video_url):\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    \"\"\"\n",
    "    gpt-3.5-turbo can handle up to 4097 tokens. Setting the chunksize to 1000 and k to 4 maximizes\n",
    "    the number of tokens to analyze.\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "    # Template to use for the system message prompt\n",
    "    template = \"\"\"\n",
    "        You are a helpful assistant that that can answer questions about youtube videos \n",
    "        based on the video's transcript: {docs}\n",
    "        \n",
    "        Only use the factual information from the transcript to answer the question.\n",
    "        \n",
    "        If you feel like you don't have enough information to answer the question, say \"I don't know\".\n",
    "        \n",
    "        Your answers should be verbose and detailed.\n",
    "        \"\"\"\n",
    "\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # Human question prompt\n",
    "    human_template = \"Answer the following question: {question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message_prompt, human_message_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "video_url = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n",
    "db = create_db_from_youtube_video_url(video_url)\n",
    "\n",
    "query = \"What are they saying about Microsoft?\"\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
